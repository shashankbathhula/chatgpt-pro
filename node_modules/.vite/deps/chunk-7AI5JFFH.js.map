{
  "version": 3,
  "sources": ["../../langchain/dist/schema/output_parser.js", "../../langchain/dist/output_parsers/noop.js", "../../langchain/dist/chains/llm_chain.js"],
  "sourcesContent": ["import { Runnable } from \"./runnable/index.js\";\n/**\n * Abstract base class for parsing the output of a Large Language Model\n * (LLM) call. It provides methods for parsing the result of an LLM call\n * and invoking the parser with a given input.\n */\nexport class BaseLLMOutputParser extends Runnable {\n    /**\n     * Parses the result of an LLM call with a given prompt. By default, it\n     * simply calls `parseResult`.\n     * @param generations The generations from an LLM call.\n     * @param _prompt The prompt used in the LLM call.\n     * @param callbacks Optional callbacks.\n     * @returns A promise of the parsed output.\n     */\n    parseResultWithPrompt(generations, _prompt, callbacks) {\n        return this.parseResult(generations, callbacks);\n    }\n    /**\n     * Calls the parser with a given input and optional configuration options.\n     * If the input is a string, it creates a generation with the input as\n     * text and calls `parseResult`. If the input is a `BaseMessage`, it\n     * creates a generation with the input as a message and the content of the\n     * input as text, and then calls `parseResult`.\n     * @param input The input to the parser, which can be a string or a `BaseMessage`.\n     * @param options Optional configuration options.\n     * @returns A promise of the parsed output.\n     */\n    async invoke(input, options) {\n        if (typeof input === \"string\") {\n            return this._callWithConfig(async (input) => this.parseResult([{ text: input }]), input, { ...options, runType: \"parser\" });\n        }\n        else {\n            return this._callWithConfig(async (input) => this.parseResult([{ message: input, text: input.content }]), input, { ...options, runType: \"parser\" });\n        }\n    }\n}\n/**\n * Class to parse the output of an LLM call.\n */\nexport class BaseOutputParser extends BaseLLMOutputParser {\n    parseResult(generations, callbacks) {\n        return this.parse(generations[0].text, callbacks);\n    }\n    async parseWithPrompt(text, _prompt, callbacks) {\n        return this.parse(text, callbacks);\n    }\n    /**\n     * Return the string type key uniquely identifying this class of parser\n     */\n    _type() {\n        throw new Error(\"_type not implemented\");\n    }\n}\n/**\n * Class to parse the output of an LLM call that also allows streaming inputs.\n */\nexport class BaseTransformOutputParser extends BaseOutputParser {\n    async *_transform(inputGenerator) {\n        for await (const chunk of inputGenerator) {\n            if (typeof chunk === \"string\") {\n                yield this.parseResult([{ text: chunk }]);\n            }\n            else {\n                yield this.parseResult([{ message: chunk, text: chunk.content }]);\n            }\n        }\n    }\n    /**\n     * Transforms an asynchronous generator of input into an asynchronous\n     * generator of parsed output.\n     * @param inputGenerator An asynchronous generator of input.\n     * @param options A configuration object.\n     * @returns An asynchronous generator of parsed output.\n     */\n    async *transform(inputGenerator, options) {\n        yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {\n            ...options,\n            runType: \"parser\",\n        });\n    }\n}\n/**\n * OutputParser that parses LLMResult into the top likely string.\n */\nexport class StringOutputParser extends BaseTransformOutputParser {\n    constructor() {\n        super(...arguments);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"schema\", \"output_parser\"]\n        });\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n    }\n    static lc_name() {\n        return \"StrOutputParser\";\n    }\n    /**\n     * Parses a string output from an LLM call. This method is meant to be\n     * implemented by subclasses to define how a string output from an LLM\n     * should be parsed.\n     * @param text The string output from an LLM call.\n     * @param callbacks Optional callbacks.\n     * @returns A promise of the parsed output.\n     */\n    parse(text) {\n        return Promise.resolve(text);\n    }\n    getFormatInstructions() {\n        return \"\";\n    }\n}\n/**\n * OutputParser that parses LLMResult into the top likely string and\n * encodes it into bytes.\n */\nexport class BytesOutputParser extends BaseTransformOutputParser {\n    constructor() {\n        super(...arguments);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"schema\", \"output_parser\"]\n        });\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"textEncoder\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: new TextEncoder()\n        });\n    }\n    static lc_name() {\n        return \"BytesOutputParser\";\n    }\n    parse(text) {\n        return Promise.resolve(this.textEncoder.encode(text));\n    }\n    getFormatInstructions() {\n        return \"\";\n    }\n}\n/**\n * Exception that output parsers should raise to signify a parsing error.\n *\n * This exists to differentiate parsing errors from other code or execution errors\n * that also may arise inside the output parser. OutputParserExceptions will be\n * available to catch and handle in ways to fix the parsing error, while other\n * errors will be raised.\n *\n * @param message - The error that's being re-raised or an error message.\n * @param llmOutput - String model output which is error-ing.\n * @param observation - String explanation of error which can be passed to a\n *     model to try and remediate the issue.\n * @param sendToLLM - Whether to send the observation and llm_output back to an Agent\n *     after an OutputParserException has been raised. This gives the underlying\n *     model driving the agent the context that the previous output was improperly\n *     structured, in the hopes that it will update the output to the correct\n *     format.\n */\nexport class OutputParserException extends Error {\n    constructor(message, llmOutput, observation, sendToLLM = false) {\n        super(message);\n        Object.defineProperty(this, \"llmOutput\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"observation\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"sendToLLM\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.llmOutput = llmOutput;\n        this.observation = observation;\n        this.sendToLLM = sendToLLM;\n        if (sendToLLM) {\n            if (observation === undefined || llmOutput === undefined) {\n                throw new Error(\"Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true\");\n            }\n        }\n    }\n}\n", "import { BaseOutputParser } from \"../schema/output_parser.js\";\n/**\n * The NoOpOutputParser class is a type of output parser that does not\n * perform any operations on the output. It extends the BaseOutputParser\n * class and is part of the LangChain's output parsers module. This class\n * is useful in scenarios where the raw output of the Large Language\n * Models (LLMs) is required.\n */\nexport class NoOpOutputParser extends BaseOutputParser {\n    constructor() {\n        super(...arguments);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"output_parsers\", \"default\"]\n        });\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n    }\n    static lc_name() {\n        return \"NoOpOutputParser\";\n    }\n    /**\n     * This method takes a string as input and returns the same string as\n     * output. It does not perform any operations on the input string.\n     * @param text The input string to be parsed.\n     * @returns The same input string without any operations performed on it.\n     */\n    parse(text) {\n        return Promise.resolve(text);\n    }\n    /**\n     * This method returns an empty string. It does not provide any formatting\n     * instructions.\n     * @returns An empty string, indicating no formatting instructions.\n     */\n    getFormatInstructions() {\n        return \"\";\n    }\n}\n", "import { BaseChain } from \"./base.js\";\nimport { BasePromptTemplate } from \"../prompts/base.js\";\nimport { BaseLanguageModel } from \"../base_language/index.js\";\nimport { NoOpOutputParser } from \"../output_parsers/noop.js\";\n/**\n * Chain to run queries against LLMs.\n *\n * @example\n * ```ts\n * import { LLMChain } from \"langchain/chains\";\n * import { OpenAI } from \"langchain/llms/openai\";\n * import { PromptTemplate } from \"langchain/prompts\";\n *\n * const prompt = PromptTemplate.fromTemplate(\"Tell me a {adjective} joke\");\n * const llm = new LLMChain({ llm: new OpenAI(), prompt });\n * ```\n */\nexport class LLMChain extends BaseChain {\n    static lc_name() {\n        return \"LLMChain\";\n    }\n    get inputKeys() {\n        return this.prompt.inputVariables;\n    }\n    get outputKeys() {\n        return [this.outputKey];\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"prompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"llm\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"llmKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"outputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"text\"\n        });\n        Object.defineProperty(this, \"outputParser\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.prompt = fields.prompt;\n        this.llm = fields.llm;\n        this.llmKwargs = fields.llmKwargs;\n        this.outputKey = fields.outputKey ?? this.outputKey;\n        this.outputParser =\n            fields.outputParser ?? new NoOpOutputParser();\n        if (this.prompt.outputParser) {\n            if (fields.outputParser) {\n                throw new Error(\"Cannot set both outputParser and prompt.outputParser\");\n            }\n            this.outputParser = this.prompt.outputParser;\n        }\n    }\n    /** @ignore */\n    _selectMemoryInputs(values) {\n        const valuesForMemory = super._selectMemoryInputs(values);\n        for (const key of this.llm.callKeys) {\n            if (key in values) {\n                delete valuesForMemory[key];\n            }\n        }\n        return valuesForMemory;\n    }\n    /** @ignore */\n    async _getFinalOutput(generations, promptValue, runManager) {\n        let finalCompletion;\n        if (this.outputParser) {\n            finalCompletion = await this.outputParser.parseResultWithPrompt(generations, promptValue, runManager?.getChild());\n        }\n        else {\n            finalCompletion = generations[0].text;\n        }\n        return finalCompletion;\n    }\n    /**\n     * Run the core logic of this chain and add to output if desired.\n     *\n     * Wraps _call and handles memory.\n     */\n    call(values, config) {\n        return super.call(values, config);\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        const valuesForPrompt = { ...values };\n        const valuesForLLM = {\n            ...this.llmKwargs,\n        };\n        for (const key of this.llm.callKeys) {\n            if (key in values) {\n                valuesForLLM[key] = values[key];\n                delete valuesForPrompt[key];\n            }\n        }\n        const promptValue = await this.prompt.formatPromptValue(valuesForPrompt);\n        const { generations } = await this.llm.generatePrompt([promptValue], valuesForLLM, runManager?.getChild());\n        return {\n            [this.outputKey]: await this._getFinalOutput(generations[0], promptValue, runManager),\n        };\n    }\n    /**\n     * Format prompt with values and pass to LLM\n     *\n     * @param values - keys to pass to prompt template\n     * @param callbackManager - CallbackManager to use\n     * @returns Completion from LLM.\n     *\n     * @example\n     * ```ts\n     * llm.predict({ adjective: \"funny\" })\n     * ```\n     */\n    async predict(values, callbackManager) {\n        const output = await this.call(values, callbackManager);\n        return output[this.outputKey];\n    }\n    _chainType() {\n        return \"llm\";\n    }\n    static async deserialize(data) {\n        const { llm, prompt } = data;\n        if (!llm) {\n            throw new Error(\"LLMChain must have llm\");\n        }\n        if (!prompt) {\n            throw new Error(\"LLMChain must have prompt\");\n        }\n        return new LLMChain({\n            llm: await BaseLanguageModel.deserialize(llm),\n            prompt: await BasePromptTemplate.deserialize(prompt),\n        });\n    }\n    /** @deprecated */\n    serialize() {\n        return {\n            _type: `${this._chainType()}_chain`,\n            llm: this.llm.serialize(),\n            prompt: this.prompt.serialize(),\n        };\n    }\n}\n"],
  "mappings": ";;;;;;;;;;;;AAMO,IAAM,sBAAN,cAAkC,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAS9C,sBAAsB,aAAa,SAAS,WAAW;AACnD,WAAO,KAAK,YAAY,aAAa,SAAS;AAAA,EAClD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAWA,MAAM,OAAO,OAAO,SAAS;AACzB,QAAI,OAAO,UAAU,UAAU;AAC3B,aAAO,KAAK,gBAAgB,OAAOA,WAAU,KAAK,YAAY,CAAC,EAAE,MAAMA,OAAM,CAAC,CAAC,GAAG,OAAO,EAAE,GAAG,SAAS,SAAS,SAAS,CAAC;AAAA,IAC9H,OACK;AACD,aAAO,KAAK,gBAAgB,OAAOA,WAAU,KAAK,YAAY,CAAC,EAAE,SAASA,QAAO,MAAMA,OAAM,QAAQ,CAAC,CAAC,GAAG,OAAO,EAAE,GAAG,SAAS,SAAS,SAAS,CAAC;AAAA,IACtJ;AAAA,EACJ;AACJ;AAIO,IAAM,mBAAN,cAA+B,oBAAoB;AAAA,EACtD,YAAY,aAAa,WAAW;AAChC,WAAO,KAAK,MAAM,YAAY,CAAC,EAAE,MAAM,SAAS;AAAA,EACpD;AAAA,EACA,MAAM,gBAAgB,MAAM,SAAS,WAAW;AAC5C,WAAO,KAAK,MAAM,MAAM,SAAS;AAAA,EACrC;AAAA;AAAA;AAAA;AAAA,EAIA,QAAQ;AACJ,UAAM,IAAI,MAAM,uBAAuB;AAAA,EAC3C;AACJ;AAwHO,IAAM,wBAAN,cAAoC,MAAM;AAAA,EAC7C,YAAY,SAAS,WAAW,aAAa,YAAY,OAAO;AAC5D,UAAM,OAAO;AACb,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,eAAe;AAAA,MACvC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,SAAK,YAAY;AACjB,SAAK,cAAc;AACnB,SAAK,YAAY;AACjB,QAAI,WAAW;AACX,UAAI,gBAAgB,UAAa,cAAc,QAAW;AACtD,cAAM,IAAI,MAAM,2EAA2E;AAAA,MAC/F;AAAA,IACJ;AAAA,EACJ;AACJ;;;ACnMO,IAAM,mBAAN,cAA+B,iBAAiB;AAAA,EACnD,cAAc;AACV,UAAM,GAAG,SAAS;AAClB,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO,CAAC,aAAa,kBAAkB,SAAS;AAAA,IACpD,CAAC;AACD,WAAO,eAAe,MAAM,mBAAmB;AAAA,MAC3C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AAAA,EACL;AAAA,EACA,OAAO,UAAU;AACb,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,MAAM;AACR,WAAO,QAAQ,QAAQ,IAAI;AAAA,EAC/B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,wBAAwB;AACpB,WAAO;AAAA,EACX;AACJ;;;AC3BO,IAAM,WAAN,MAAM,kBAAiB,UAAU;AAAA,EACpC,OAAO,UAAU;AACb,WAAO;AAAA,EACX;AAAA,EACA,IAAI,YAAY;AACZ,WAAO,KAAK,OAAO;AAAA,EACvB;AAAA,EACA,IAAI,aAAa;AACb,WAAO,CAAC,KAAK,SAAS;AAAA,EAC1B;AAAA,EACA,YAAY,QAAQ;AAChB,UAAM,MAAM;AACZ,WAAO,eAAe,MAAM,mBAAmB;AAAA,MAC3C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,UAAU;AAAA,MAClC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,OAAO;AAAA,MAC/B,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,aAAa;AAAA,MACrC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AACD,SAAK,SAAS,OAAO;AACrB,SAAK,MAAM,OAAO;AAClB,SAAK,YAAY,OAAO;AACxB,SAAK,YAAY,OAAO,aAAa,KAAK;AAC1C,SAAK,eACD,OAAO,gBAAgB,IAAI,iBAAiB;AAChD,QAAI,KAAK,OAAO,cAAc;AAC1B,UAAI,OAAO,cAAc;AACrB,cAAM,IAAI,MAAM,sDAAsD;AAAA,MAC1E;AACA,WAAK,eAAe,KAAK,OAAO;AAAA,IACpC;AAAA,EACJ;AAAA;AAAA,EAEA,oBAAoB,QAAQ;AACxB,UAAM,kBAAkB,MAAM,oBAAoB,MAAM;AACxD,eAAW,OAAO,KAAK,IAAI,UAAU;AACjC,UAAI,OAAO,QAAQ;AACf,eAAO,gBAAgB,GAAG;AAAA,MAC9B;AAAA,IACJ;AACA,WAAO;AAAA,EACX;AAAA;AAAA,EAEA,MAAM,gBAAgB,aAAa,aAAa,YAAY;AACxD,QAAI;AACJ,QAAI,KAAK,cAAc;AACnB,wBAAkB,MAAM,KAAK,aAAa,sBAAsB,aAAa,aAAa,yCAAY,UAAU;AAAA,IACpH,OACK;AACD,wBAAkB,YAAY,CAAC,EAAE;AAAA,IACrC;AACA,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAMA,KAAK,QAAQ,QAAQ;AACjB,WAAO,MAAM,KAAK,QAAQ,MAAM;AAAA,EACpC;AAAA;AAAA,EAEA,MAAM,MAAM,QAAQ,YAAY;AAC5B,UAAM,kBAAkB,EAAE,GAAG,OAAO;AACpC,UAAM,eAAe;AAAA,MACjB,GAAG,KAAK;AAAA,IACZ;AACA,eAAW,OAAO,KAAK,IAAI,UAAU;AACjC,UAAI,OAAO,QAAQ;AACf,qBAAa,GAAG,IAAI,OAAO,GAAG;AAC9B,eAAO,gBAAgB,GAAG;AAAA,MAC9B;AAAA,IACJ;AACA,UAAM,cAAc,MAAM,KAAK,OAAO,kBAAkB,eAAe;AACvE,UAAM,EAAE,YAAY,IAAI,MAAM,KAAK,IAAI,eAAe,CAAC,WAAW,GAAG,cAAc,yCAAY,UAAU;AACzG,WAAO;AAAA,MACH,CAAC,KAAK,SAAS,GAAG,MAAM,KAAK,gBAAgB,YAAY,CAAC,GAAG,aAAa,UAAU;AAAA,IACxF;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAaA,MAAM,QAAQ,QAAQ,iBAAiB;AACnC,UAAM,SAAS,MAAM,KAAK,KAAK,QAAQ,eAAe;AACtD,WAAO,OAAO,KAAK,SAAS;AAAA,EAChC;AAAA,EACA,aAAa;AACT,WAAO;AAAA,EACX;AAAA,EACA,aAAa,YAAY,MAAM;AAC3B,UAAM,EAAE,KAAK,OAAO,IAAI;AACxB,QAAI,CAAC,KAAK;AACN,YAAM,IAAI,MAAM,wBAAwB;AAAA,IAC5C;AACA,QAAI,CAAC,QAAQ;AACT,YAAM,IAAI,MAAM,2BAA2B;AAAA,IAC/C;AACA,WAAO,IAAI,UAAS;AAAA,MAChB,KAAK,MAAM,kBAAkB,YAAY,GAAG;AAAA,MAC5C,QAAQ,MAAM,mBAAmB,YAAY,MAAM;AAAA,IACvD,CAAC;AAAA,EACL;AAAA;AAAA,EAEA,YAAY;AACR,WAAO;AAAA,MACH,OAAO,GAAG,KAAK,WAAW,CAAC;AAAA,MAC3B,KAAK,KAAK,IAAI,UAAU;AAAA,MACxB,QAAQ,KAAK,OAAO,UAAU;AAAA,IAClC;AAAA,EACJ;AACJ;",
  "names": ["input"]
}
